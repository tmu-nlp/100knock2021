{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knock70.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UNfrqSnZ4EsakbFKUgZOtiFtzzUjp_nl",
      "authorship_tag": "ABX9TyMyt7NJ4qTnuGNcXA5cl+bw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmu-nlp/100knock2021/blob/main/wei/chapter08/knock70.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwXrktkv9ro3"
      },
      "source": [
        "## Task Description   \n",
        "70. 単語ベクトルの和による特徴量\n",
        "\n",
        "\n",
        "*   学習データについて，すべての事例xi(r.v.)の特徴ベクトルxiを並べた行列Xと，正解ラベルを並べた行列（ベクトル）Yを作成する。ラベルの種類数をL(L=4)で表す.\n",
        "*  i番目の事例はTi個の（記事見出しの）単語列(wi,1,wi,2,…,wi,Ti)から構成される。即ち、i番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものがxiである学習データ、検証データ、評価データそれぞれの特徴量行列及びラベルベクトルを作成し、ファイルに保存 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XFTLKixCEro"
      },
      "source": [
        "#　!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afBPPoNenhd_"
      },
      "source": [
        "# !unzip NewsAggregatorDataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z3vTsZQno5t"
      },
      "source": [
        "# 読込時のエラー回避のためダブルクォーテーションをシングルクォーテーションに置換\n",
        "!sed -e 's/\"/'\\''/g' drive/MyDrive/ColabNotebooks/NLPknock100/newsCorpora.csv > drive/MyDrive/ColabNotebooks/NLPknock100/newsCorpora_re.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbW3OaN7DnEB"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "df = pd.read_csv('drive/MyDrive/ColabNotebooks/NLPknock100/newsCorpora_re.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "\n",
        "# データの抽出\n",
        "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "\n",
        "# データの分割\n",
        "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n",
        "\n",
        "# 事例数の確認\n",
        "print('【学習データ】')\n",
        "print(train['CATEGORY'].value_counts())\n",
        "print('【検証データ】')\n",
        "print(valid['CATEGORY'].value_counts())\n",
        "print('【評価データ】')\n",
        "print(test['CATEGORY'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWtDXaYLKAUR"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# 学習済み単語ベクトルを読み込む\n",
        "model = KeyedVectors.load_word2vec_format('drive/MyDrive/ColabNotebooks/NLPknock100/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOFWt9jnKFf-"
      },
      "source": [
        "import string\n",
        "import torch\n",
        "\n",
        "def transform_w2v(text):\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()  # 記号をスペースに置換後、スペースで分割してリスト化\n",
        "  vec = [model[word] for word in words if word in model]  # 1語ずつベクトル化\n",
        "\n",
        "  return torch.tensor(sum(vec) / len(vec))  # 平均ベクトルをTensor型に変換して出力"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA9Sk9wdKIQk"
      },
      "source": [
        "# 特徴ベクトルの作成\n",
        "X_train = torch.stack([transform_w2v(text) for text in train['TITLE']])\n",
        "X_valid = torch.stack([transform_w2v(text) for text in valid['TITLE']])\n",
        "X_test = torch.stack([transform_w2v(text) for text in test['TITLE']])\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZxD49dOKZha"
      },
      "source": [
        "# ラベルベクトルの作成\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "y_train = torch.tensor(train['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_valid = torch.tensor(valid['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_test = torch.tensor(test['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "\n",
        "print(y_train.size())\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYio6c2pMUOs"
      },
      "source": [
        "# 保存\n",
        "data_dir = 'drive/MyDrive/ColabNotebooks/NLPknock100/chapter08/data/'\n",
        "torch.save(X_train, data_dir + 'X_train.pt')\n",
        "torch.save(X_valid, data_dir + 'X_valid.pt')\n",
        "torch.save(X_test, data_dir + 'X_test.pt')\n",
        "torch.save(y_train, data_dir + 'y_train.pt')\n",
        "torch.save(y_valid, data_dir + 'y_valid.pt')\n",
        "torch.save(y_test, data_dir + 'y_test.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vBEiHu-R2OP"
      },
      "source": [
        "!ls drive/MyDrive/ColabNotebooks/NLPknock100/chapter08/data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}