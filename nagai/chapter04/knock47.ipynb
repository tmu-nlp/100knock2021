{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "96c4d2ae-8fb4-4b07-a4c0-5fdf4276cd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理を用いる \t\t\n",
      "注目を集める \tが  \tサポートベクターマシンが  \n",
      "学習を行う \tに  を  \t元に  経験を  \n",
      "流行を超える \tの  \t一過性の  \n",
      "学習を繰り返す \tや  \t開発や  \n",
      "進化を見せる \tて  て  において  は  \t活躍して  加えて  生成技術において  敵対的生成ネットワークは  \n",
      "生成を行う \tという  \tCreativeAIという  \n",
      "開発を行う \tの  は  \t機械式計算機の  エイダ・ラブレスは  \n",
      "処理を行う \t\t\n",
      "処理を行う \tに  に  により  \t同年に  Webに  ティム・バーナーズリーにより  \n",
      "処理を行う \tて  に  \t付加して  コンピュータに  \n",
      "研究を進める \tて  の  \t費やして  第五世代コンピュータの  \n",
      "注目を集める \tから  の  は  \tことから  世間の  ファジィは  \n",
      "成功を受ける \tの  \t試みの  \n",
      "制御を用いる \tて  の  も  \t受けて  同様の  他社も  \n",
      "進歩を担う \tの  \t科学技術の  \n",
      "改善を果たす \tから  が  で  に  の  \t従来手法から  チームが  画像処理コンテストで  2012年に  従来手法からの  \n",
      "プログラムを使う \tにあたる  \t解析にあたる  \n",
      "研究を続ける \tが  て  \tジェフホーキンスが  向けて  \n",
      "注目を集める \tに  の  \t急速に  識者の  \n",
      "普及を受ける \tと  \t発明と  \n",
      "学習を組み合わせる \tと  \t神経科学と  \n",
      "投資を行う \tで  に  \t民間企業主導で  全世界的に  \n",
      "探索を行う \tで  \t無報酬で  \n",
      "研究を始める \tとも  は  \tマックスプランク研究所とも  Googleは  \n",
      "研究を行う \tて  という  \t始めて  再構成するという  \n",
      "実験をする \tの  や  \t新技術の  研究や  \n",
      "投資をする \tに  は  まで  \t2022年までに  韓国は  2022年まで  \n",
      "シミュレーションを行う \t\t\n",
      "反乱を起こす \tて  に対して  \t於いて  人間に対して  \n",
      "弾圧を併せ持つ \tと  の  \t資金力と  人権の  \n",
      "手続きを経る \tを  \tウイグル族を  \n",
      "差別を認める \tで  による  の  のみ  \t融資で  ビッグデータ分析のみによる  融資での  ビッグデータ分析のみ  \n",
      "展開を変える \tの  \t部隊の  \n",
      "判断を介す \tから  の  \t観点から  人間の  \n",
      "禁止を求める \tが  に  の  は  \tヒューマン・ライツ・ウォッチが  4月に  自動操縦型武器の  4月には  \n",
      "運用をめぐる \tの  \tAI兵器の  \n",
      "試験を行う \tの  \t世界最大規模の  \n",
      "追及を受ける \tて  で  で  と  とともに  は  \t暴露されて  公聴会で  整合性で  拒否すると  とともに  公聴会では  \n",
      "存在を見いだす \tに  \tものに  \n",
      "話をする \tの  は  \t異界の  哲学者は  \n",
      "疎通を行う \t\t\n",
      "勘違いをする \t\t\n",
      "議論を行う \tまで  \tこれまで  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pydot_ng as pydot\n",
    "class Morph:\n",
    "    def __init__(self,item):\n",
    "        self.surface=item[0]\n",
    "        self.base=item[len(items)-3]\n",
    "        self.pos=items[1]\n",
    "        self.pos1=items[2] \n",
    "        \n",
    "class Chunk:\n",
    "    def __init__(self,idx,dst):\n",
    "        self.idx = idx     \n",
    "        self.morphs = []   \n",
    "        self.dst = dst     \n",
    "        self.srcs = [] \n",
    "        \n",
    "with open(\"ai.ja.txt.parsed\",\"r\",encoding=\"utf-8\") as ai:\n",
    "    result=[]\n",
    "    sent=[]\n",
    "    for line in ai:\n",
    "        line=line.strip()\n",
    "        items=re.split(\"[ ,\\t]\",line)\n",
    "        if items[0]==\"*\":\n",
    "            idx=int(items[1])\n",
    "            items[2]=items[2].strip(\"D\")\n",
    "            dst=int(items[2])\n",
    "            chunk=Chunk(idx,dst)\n",
    "            sent.append(chunk)\n",
    "            \n",
    "        elif items[0]==\"EOS\":\n",
    "            if sent:\n",
    "                result.append(sent)\n",
    "                sent=[]\n",
    "            \n",
    "        else:\n",
    "            chunk.morphs.append(Morph(items))\n",
    "            \n",
    "    for sen in result:\n",
    "        for chunk in sen:\n",
    "            if chunk.dst!=-1:\n",
    "                sen[int(chunk.dst)].srcs.append(chunk.idx)\n",
    "    \n",
    "#47\n",
    "    kakariuke=[]\n",
    "    joshi={}\n",
    "    kou=[]\n",
    "    kous={}\n",
    "    for sent in result:\n",
    "        for chunk in sent:\n",
    "            if chunk.dst!=-1:\n",
    "                moto=[k.base if k.pos!=\"記号\" else \"\" for k in chunk.morphs]\n",
    "                moto_sur=[k.surface if k.pos!=\"記号\" else \"\" for k in chunk.morphs]\n",
    "                saki=[k.base if k.pos!=\"記号\" else \"\" for k in sent[int(chunk.dst)].morphs]\n",
    "                moto_pos=[k.pos if k.pos!=\"記号\" else \"\" for k in chunk.morphs]\n",
    "                saki_pos=[k.pos if k.pos!=\"記号\" else \"\" for k in sent[int(chunk.dst)].morphs]\n",
    "                \n",
    "                for k in range(len(chunk.morphs)-1):\n",
    "                    if chunk.morphs[k].pos1==\"サ変接続\" and chunk.morphs[k+1].base==\"を\":\n",
    "                        if saki_pos[0]==\"動詞\" and int(chunk.idx)+1==int(chunk.dst):\n",
    "                            print(chunk.morphs[k].base+chunk.morphs[k+1].surface+saki[0],\"\\t\",end=\"\")\n",
    "                            \n",
    "                            meishi_wo=chunk.idx\n",
    "                            dousi=chunk.dst\n",
    "                            p=0\n",
    "                            for chunk in sent:\n",
    "                                if meishi_wo==chunk.dst or dousi==chunk.dst:\n",
    "                                    if chunk.idx==meishi_wo: continue\n",
    "                                    moto=[k.base if k.pos!=\"記号\" else \"\" for k in chunk.morphs]\n",
    "                                    moto_pos=[k.pos if k.pos!=\"記号\" else \"\" for k in chunk.morphs]\n",
    "                                    moto_sur=[k.surface if k.pos!=\"記号\" else \"\" for k in chunk.morphs]\n",
    "                                    \n",
    "                                    if \"助詞\" in moto_pos:\n",
    "                                        for k2 in range(len(chunk.morphs)):\n",
    "                                            if chunk.morphs[k2].pos==\"助詞\":\n",
    "                                                joshi[p]=moto[k2]\n",
    "                                            \n",
    "                                                kou=[moto_sur[i] for i in range(k2,-1,-1)]\n",
    "                                                kou.reverse()\n",
    "                                        \n",
    "                                                kous[p]=kou\n",
    "                                                p+=1\n",
    "                            sort_joshi=sorted(joshi.items(),key=lambda x:x[1])\n",
    "                            #print(sort_joshi,\"\\t\",end=\"\")\n",
    "                            for value in sort_joshi:\n",
    "                                print(value[1],\" \",end=\"\")\n",
    "                                \n",
    "                            print(\"\\t\",end=\"\")\n",
    "                            for num in sort_joshi:\n",
    "                                print(\"\".join(kous[num[0]]),\" \",end=\"\")\n",
    "                                \n",
    "            \n",
    "                            joshi={}\n",
    "                            kous={}\n",
    "                            print()\n",
    "                                       \n",
    "                \n",
    "                        \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2e7dd-8887-406a-a372-2dd5ea15f74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9064af-d5a2-4dd1-9e0a-fad35d258be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
