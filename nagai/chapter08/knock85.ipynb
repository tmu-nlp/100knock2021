{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b02441da-e225-4b90-a2a3-a95988f4109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\ttrain:\tloss:1.128151297569275\taccuracy:0.5059880239520959\tvalid:\tloss:1.12944495677948\taccuracy:0.5065518532384875\n",
      "epoch:1\ttrain:\tloss:1.0894862413406372\taccuracy:0.5276946107784432\tvalid:\tloss:1.09335458278656\taccuracy:0.5406214900786223\n",
      "epoch:2\ttrain:\tloss:1.0544825792312622\taccuracy:0.5464071856287425\tvalid:\tloss:1.0604034662246704\taccuracy:0.5641145638337701\n",
      "epoch:3\ttrain:\tloss:1.0180913209915161\taccuracy:0.5808383233532934\tvalid:\tloss:1.0248441696166992\taccuracy:0.5935043055035567\n",
      "epoch:4\ttrain:\tloss:0.9795293211936951\taccuracy:0.6130239520958084\tvalid:\tloss:0.9857911467552185\taccuracy:0.6198053163609135\n",
      "epoch:5\ttrain:\tloss:0.9391775131225586\taccuracy:0.6399700598802395\tvalid:\tloss:0.9439021944999695\taccuracy:0.6427368026956196\n",
      "epoch:6\ttrain:\tloss:0.8979808688163757\taccuracy:0.6616766467065869\tvalid:\tloss:0.900333046913147\taccuracy:0.6686634219393486\n",
      "epoch:7\ttrain:\tloss:0.8579407930374146\taccuracy:0.6923652694610778\tvalid:\tloss:0.8572514057159424\taccuracy:0.6871958068139273\n",
      "epoch:8\ttrain:\tloss:0.8210465908050537\taccuracy:0.7125748502994012\tvalid:\tloss:0.8173490762710571\taccuracy:0.7036690378135529\n",
      "epoch:9\ttrain:\tloss:0.7914548516273499\taccuracy:0.7260479041916168\tvalid:\tloss:0.7855873107910156\taccuracy:0.7134032197678772\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import collections\n",
    "import numpy as np\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab,emb,pad,out,hid,num_layers,emb_weights=None,bidirectional=False):\n",
    "        super().__init__()        \n",
    "        if emb_weights!=None:\n",
    "            self.emb=nn.Embedding.from_pretrained(emb_weights,padding_idx=pad)\n",
    "        else:\n",
    "            self.emb=nn.Embedding(vocab,emb,padding_idx=pad)\n",
    "        self.rnn=nn.RNN(emb,hid,bidirectional=bidirectional,batch_first=True)\n",
    "        self.rnn2=nn.RNN(2*hid,hid,bidirectional=bidirectional,batch_first=True)\n",
    "        self.rnn3=nn.RNN(2*hid,hid,bidirectional=bidirectional,batch_first=True)\n",
    "        self.rnn4=nn.RNN(2*hid,hid,bidirectional=bidirectional,batch_first=True)\n",
    "        self.linear=nn.Linear(2*hid,out)\n",
    "        self.softmax=torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self,x,h=None):\n",
    "        x=self.emb(x)\n",
    "        y,h=self.rnn(x,h)\n",
    "        y,h=self.rnn2(y,h)\n",
    "        y,h=self.rnn3(y,h)\n",
    "        y,h=self.rnn4(y,h)\n",
    "        y=y[:,-1,:]\n",
    "        y=self.linear(y)\n",
    "        return y\n",
    "    \n",
    "def accuracy(pred,label):\n",
    "    pred=torch.argmax(pred,dim=-1)\n",
    "    leng=len(pred)\n",
    "    return (pred==label).sum().item()/leng\n",
    "\n",
    "def list2tensor(data,max_len,pad):\n",
    "    new_list=[]\n",
    "    for d in data:\n",
    "        if len(d)>max_len:\n",
    "            d=d[:max_len]\n",
    "        else:\n",
    "            d+=[pad]*(max_len-len(d))\n",
    "        new_list.append(d)\n",
    "    return torch.tensor(new_list)\n",
    "\n",
    "def count(file):\n",
    "    all_word=[]\n",
    "    with open(file,\"r\",encoding=\"utf-8\") as tf:\n",
    "        tags=[]\n",
    "        tag_num={\"b\":0,\"t\":1,\"e\":2,\"m\":3}\n",
    "        for line in tf:\n",
    "            line.strip();\n",
    "            tag,sen=line.split(\"\\t\")\n",
    "            tags.append(tag_num[tag])\n",
    "            words=sen.strip().split(\" \")\n",
    "            for word in words:\n",
    "                all_word.append(word)\n",
    "        freq=collections.Counter(all_word)\n",
    "        freq_sort=sorted(freq.items(),key=lambda x:x[1],reverse=True)\n",
    "        #print(freq_sort)\n",
    "        word_number={w:i+1 for i,(w,f) in enumerate(freq_sort) if f>=2}\n",
    "        return word_number,tags\n",
    "\n",
    "def id_v(file,word_id):\n",
    "    with open(file,\"r\",encoding=\"utf-8\") as tf:\n",
    "        ids=[]\n",
    "        for line in tf:\n",
    "            line.strip();\n",
    "            tag,sen=line.split(\"\\t\")\n",
    "            words=sen.strip().split(\" \")\n",
    "            sent_ids=[]\n",
    "            for word in words:\n",
    "                if word in word_id:\n",
    "                    sent_ids.append(word_id[word])\n",
    "                else:\n",
    "                    sent_ids.append(0)\n",
    "            ids.append(sent_ids)\n",
    "        return ids\n",
    "    \n",
    "word_id,Y_train=count(\"train.feature.txt\")\n",
    "word_id_valid,Y_valid=count(\"valid.feature.txt\")\n",
    "max_len=10\n",
    "vocab=len(word_id)+1\n",
    "emb=300\n",
    "pad=len(word_id)\n",
    "hid=50\n",
    "out=4\n",
    "num_layers=2\n",
    "\n",
    "X_train=id_v(\"train.feature.txt\",word_id)\n",
    "X_train=list2tensor(X_train,max_len,pad)\n",
    "Y_train=torch.tensor(Y_train)\n",
    "\n",
    "X_valid=id_v(\"valid.feature.txt\",word_id)\n",
    "X_valid=list2tensor(X_valid,max_len,pad)\n",
    "Y_valid=torch.tensor(Y_valid)\n",
    "\n",
    "model=RNN(vocab,emb,pad,out,hid,num_layers,emb_weights=None,bidirectional=True)\n",
    "\n",
    "dataset_train=TensorDataset(X_train,Y_train)\n",
    "\n",
    "loader=DataLoader(dataset_train,batch_size=1024)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "epoch=10\n",
    "for num in range(epoch):\n",
    "    for X,Y in loader:\n",
    "        Y_pred=model(X)\n",
    "        loss=loss_fn(Y_pred,Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        Y_pred=model(X_train)\n",
    "        loss=loss_fn(Y_pred,Y_train)\n",
    "        ac=accuracy(Y_pred,Y_train)\n",
    "        \n",
    "        Y_pred_v=model(X_valid)\n",
    "        loss_v=loss_fn(Y_pred_v,Y_valid)\n",
    "        ac_v=accuracy(Y_pred_v,Y_valid)\n",
    "        print(f\"epoch:{num}\\ttrain:\\tloss:{loss}\\taccuracy:{ac}\\tvalid:\\tloss:{loss_v}\\taccuracy:{ac_v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966c60a-c265-4847-97c0-6f6aba43dafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c69d17-d87a-4185-83ee-1c97a84f5468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
